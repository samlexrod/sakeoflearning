{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"!pip install pyarrow"},{"cell_type":"code","execution_count":159,"metadata":{},"outputs":[],"source":"import boto3\nimport pandas as pd\nimport pyarrow as pa\nfrom s3fs import S3FileSystem\nimport pyarrow.parquet as pq\nimport os\nimport time\nfrom datetime import datetime as dt"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"client_id = 'BCMA'\nreceived_date = '2019-01-01'\n\n# declaring variables\nclient_id = client_id.lower()\nreceived_date = 'RD-'+pd.to_datetime(received_date).strftime(\"%Y-%m-%d\")\ndatabase = client_id+'_'+received_date\ns3_path = os.path.join('s3://prospect-raw-files/', client_id, received_date)"},{"cell_type":"markdown","metadata":{},"source":["# Read and Write Functions from CSV to Parquet    "]},{"cell_type":"code","execution_count":181,"metadata":{},"outputs":[],"source":"def read_objects():\n    \"\"\"\n    \n    \"\"\"\n    all_objects = s3.list_objects(Bucket='prospect-raw-files')\n    \n    target_files = lambda key: '.csv' in key and received_date in key\n    target_keys = list(filter(target_files, [cont.get('Key') for cont in all_objects['Contents']]))\n    \n    obj_dict = {'Body': [], 'Key': [], 'DelKey': []}\n    for key in target_keys:\n        obj = s3.get_object(Bucket='prospect-raw-files', Key=key)\n        obj_dict['Body'].append(obj['Body'])\n        obj_dict['Key'].append(os.path.dirname(key))\n        obj_dict['DelKey'].append(key)\n    return obj_dict\n\ndef write_parquet(obj_dict, delete_source=False):\n    \"\"\"\n    \n    \"\"\"\n    objs_keys = list(zip(target_obj.get('Body'), target_obj.get('Key'), target_obj.get('DelKey')))\n    for obj, key, delkey in objs_keys:\n        print(obj)\n        df = pd.read_csv(obj)\n        table = pa.Table.from_pandas(df)\n        print(os.path.join('s3://', key))\n        pq.write_to_dataset(\n            table=table, \n            root_path=os.path.join('s3://prospect-raw-files', key), \n            filesystem=S3FileSystem()\n        ) \n        print(delkey)\n\n        if delete_source:\n            s3.delete_object(Bucket='prospect-raw-files', Key=delkey)"},{"cell_type":"markdown","metadata":{},"source":["# s3: Start with File Convertion to Parquet"]},{"cell_type":"code","execution_count":182,"metadata":{},"outputs":[],"source":"s3 = boto3.client('s3',region_name='us-east-1')"},{"cell_type":"markdown","metadata":{},"source":["### 1. Convert all csv files to parquet files  (delete or move raw files to cold storage)"]},{"cell_type":"code","execution_count":183,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<botocore.response.StreamingBody object at 0x7f24281b1f28>\n","s3://bcma/RD-2019-01-01/ClientData\n","bcma/RD-2019-01-01/ClientData/ClaimDataExample1.csv\n","<botocore.response.StreamingBody object at 0x7f2428107550>\n","s3://bcma/RD-2019-01-01/ClientData\n","bcma/RD-2019-01-01/ClientData/ClaimDataExample2.csv\n","<botocore.response.StreamingBody object at 0x7f2428107940>\n","s3://bcma/RD-2019-01-01/ClientData\n","bcma/RD-2019-01-01/ClientData/ClaimDataExample3.csv\n","<botocore.response.StreamingBody object at 0x7f2428107e80>\n","s3://bcma/RD-2019-01-01/ControlFile\n","bcma/RD-2019-01-01/ControlFile/ControlDataExample.csv\n","<botocore.response.StreamingBody object at 0x7f2428104400>\n","s3://bcma/RD-2019-01-01/MembershipData\n","bcma/RD-2019-01-01/MembershipData/MemberDataExample.csv\n"]}],"source":"target_obj = read_objects()\nwrite_parquet(target_obj, delete_source=True)"},{"cell_type":"markdown","metadata":{},"source":["# glue: Continue with Ad-Hoc Crawler"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"glue_client = boto3.client('glue', region_name='us-east-1')"},{"cell_type":"markdown","metadata":{},"source":["### 1. Creating Ad-Hoc Database\n","This database is designed to catalogue raw tables related to this client. For this process, if only one table is created, then the data is ready to be transformed to parquet."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["{'ResponseMetadata': {'RequestId': '55abe334-fcbc-11e9-98e3-ed5f070bbc84',\n","  'HTTPStatusCode': 200,\n","  'HTTPHeaders': {'date': 'Fri, 01 Nov 2019 15:29:03 GMT',\n","   'content-type': 'application/x-amz-json-1.1',\n","   'content-length': '2',\n","   'connection': 'keep-alive',\n","   'x-amzn-requestid': '55abe334-fcbc-11e9-98e3-ed5f070bbc84'},\n","  'RetryAttempts': 0}}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":"glue_client.create_database(\n    DatabaseInput={\n        'Name': database\n    }\n)"},{"cell_type":"markdown","metadata":{},"source":["### 2. Creating the Ad-Hoc Crawler\n","This crawler is designed to go over this particular prospect dataset only. Thus, it will catalogue tables only for this dataset."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["{'ResponseMetadata': {'RequestId': 'd7728af6-fcbc-11e9-9632-3df273b52ac1',\n","  'HTTPStatusCode': 200,\n","  'HTTPHeaders': {'date': 'Fri, 01 Nov 2019 15:32:41 GMT',\n","   'content-type': 'application/x-amz-json-1.1',\n","   'content-length': '2',\n","   'connection': 'keep-alive',\n","   'x-amzn-requestid': 'd7728af6-fcbc-11e9-9632-3df273b52ac1'},\n","  'RetryAttempts': 0}}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":"crawler_name = client_id.lower()+'-raw-crawler_'+received_date\nglue_client.create_crawler(\n    Name=crawler_name,\n    Role='UnderwritingServiceRole',\n    DatabaseName=database.lower(),\n    Description='Automated Single Usage - Delete after use',\n    Targets={\n        'S3Targets': [\n            {'Path': s3_path}\n        ]\n    }\n)"},{"cell_type":"markdown","metadata":{},"source":["### 3. Running Crawler\n","Running the crawler will map the data in the selected s3 bucket into catalogue tables."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["It should be stopping now!\n"]}],"source":"glue_client.start_crawler(Name=crawler_name)\ntime.sleep(60)\nprint(\"It should be stopping now!\")"},{"cell_type":"markdown","metadata":{},"source":["### 4. Delete Ad-Hoc Crawler"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["{'ResponseMetadata': {'RequestId': 'f3effafa-fcbd-11e9-90fb-3500b9f55e40',\n","  'HTTPStatusCode': 200,\n","  'HTTPHeaders': {'date': 'Fri, 01 Nov 2019 15:40:38 GMT',\n","   'content-type': 'application/x-amz-json-1.1',\n","   'content-length': '2',\n","   'connection': 'keep-alive',\n","   'x-amzn-requestid': 'f3effafa-fcbd-11e9-90fb-3500b9f55e40'},\n","  'RetryAttempts': 0}}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":"glue_client.delete_crawler(Name=crawler_name)"},{"cell_type":"markdown","metadata":{},"source":["# Continue with Athena Queries"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"athena_client = boto3.client('athena', region_name='us-east-1')"},{"cell_type":"markdown","metadata":{},"source":["### 1. Creating claim data query"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"ename":"ClientError","evalue":"An error occurred (AccessDeniedException) when calling the CreateNamedQuery operation: User: arn:aws:sts::133469299809:assumed-role/AWSGlueServiceSageMakerNotebookRole-adv_underwriting/SageMaker is not authorized to perform: athena:CreateNamedQuery on resource: arn:aws:athena:us-east-1:133469299809:workgroup/primary","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-f0b184142f37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ClaimData'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mDatabase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mQueryString\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SELECT * FROM clientdata\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n","\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mClientError\u001b[0m: An error occurred (AccessDeniedException) when calling the CreateNamedQuery operation: User: arn:aws:sts::133469299809:assumed-role/AWSGlueServiceSageMakerNotebookRole-adv_underwriting/SageMaker is not authorized to perform: athena:CreateNamedQuery on resource: arn:aws:athena:us-east-1:133469299809:workgroup/primary"]}],"source":"athena_client.create_named_query(\n    Name='ClaimData',\n    Database=database,\n    QueryString=\"SELECT * FROM clientdata\"\n)"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}