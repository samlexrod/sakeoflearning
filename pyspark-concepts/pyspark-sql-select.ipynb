{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('SQLTutorial').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting from sklearn\n",
    "breast_cancer = sklearn.datasets.load_breast_cancer()\n",
    "\n",
    "# mapping binary labels to target nambes\n",
    "target_map = dict(zip([1, 0], breast_cancer['target_names']))\n",
    "\n",
    "# creating the label names dataframe\n",
    "df_target = pd.DataFrame(breast_cancer['target'], columns=['cancer_type']).apply(lambda x: x.map(target_map))\n",
    "\n",
    "# creating the feature dataframe\n",
    "df = pd.DataFrame(breast_cancer['data'], columns=breast_cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump flat data for pyspark load tutorial\n",
    "df_target.to_csv('../tutorial-data/breast_cancer_target.csv', index_label='datakey')\n",
    "df.to_csv('../tutorial-data/breast_cancer_features.csv', index_label='datakey')\n",
    "df_target.to_json('../tutorial-data/breast_cancer_target.json')\n",
    "df.to_json('../tutorial-data/breast_cancer_features.json')\n",
    "df_target.to_parquet('../tutorial-data/breast_cancer_target.parquet', index=True)\n",
    "df.to_parquet('../tutorial-data/breast_cancer_features.parquet', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Both Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Join Type 1: pd.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_target, df], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Join Type 2: df.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target.join(df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = df_target.join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Resilient Distributed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "df_rdd = spark.createDataFrame(df_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Temp SQL Table Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rdd.createOrReplaceTempView('SqlTutorial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Comparisons: SQL and Dot Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1: Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rdd.limit(10).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM SqlTutorial\n",
    "LIMIT 10\n",
    "\"\"\").toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2: Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rdd.groupBy('cancer_type')\\\n",
    "    .agg({'mean radius':'mean'})\\\n",
    "    .withColumnRenamed('avg(mean radius)', 'AvgMeanRadius')\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    cancer_type AS CancerType,\n",
    "    AVG(`mean radius`) AS AvgMedianRadius\n",
    "FROM SqlTutorial\n",
    "GROUP BY cancer_type\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3: Window and Aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lead\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy('cancer_type').orderBy('mean radius')\n",
    "\n",
    "df_rdd.withColumn(\n",
    "    'next radius', \n",
    "    lead('mean radius', 1).over(window)\n",
    ").select(['mean radius', 'next radius']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    `mean radius`,\n",
    "    LEAD(`mean radius`) \n",
    "        OVER(PARTITION BY cancer_type ORDER BY `mean radius`) AS `next radius`\n",
    "FROM SqlTutorial\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
