{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc1dc9a6-ac89-4bf3-8edc-2f14d66457ce",
   "metadata": {},
   "source": [
    "# One Versus Rest & One Versis One"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61443df-d7b5-4066-84cd-c0b913cf2c5a",
   "metadata": {},
   "source": [
    "## Iris Dataset Example\n",
    "The iris dataset is a classic and very easy multi-class classification dataset.\n",
    "This dataset consists of 3 different types of irisesâ€™ (Setosa, Versicolour, and Virginica) \n",
    "petal and sepal length, stored in a 150x4 numpy.ndarray.\n",
    "\n",
    "It helps to understand the basic steps of training a multi-class classification model in \n",
    "a very simple and easy-to-understand dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fce8d15-81dc-4cef-848f-f2407d6e6ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-Rest with XGBoost Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# Wrap the XGBoost model with OneVsRestClassifier\n",
    "ovr_model = OneVsRestClassifier(xgb_model)\n",
    "\n",
    "# Train the OneVsRest model\n",
    "ovr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ovr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"One-vs-Rest with XGBoost Accuracy:\", accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015df2b-81c9-4ee0-9f8a-70b9aad5daf4",
   "metadata": {},
   "source": [
    "# Customer Segmentation Example\n",
    "\n",
    "By using segmented customer data, we can achieve better model performance by training separate models for each segment.\n",
    "In this approach, we are generating synthetic customer data with random values for the features and segmenting the \n",
    "customers into three segments: 'High Value', 'Medium Value', and 'Low Value'.\n",
    "\n",
    "However, in a real-world scenario, you would use actual customer data and segment the customers based on their behavior,\n",
    "such as purchase history, spending patterns, etc. This means that you will not achieve the same level of accuracy as in\n",
    "this synthetic example, but the concept of segmenting customers and training separate models for each segment still applies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b903966-51a4-43c9-a832-04ae3051b2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 1.0\n",
      "Predicted Segments: ['High Value' 'High Value' 'Medium Value' ... 'Medium Value' 'Low Value'\n",
      " 'Low Value']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def segmented_anual_spending(segment):\n",
    "    \"\"\"\n",
    "    Generate a random annual spending based on the segment.\n",
    "    \"\"\"\n",
    "    if segment == 'High Value':\n",
    "        return np.random.uniform(10000, 20000)\n",
    "    elif segment == 'Medium Value':\n",
    "        return np.random.uniform(5000, 10000)\n",
    "    else:\n",
    "        return np.random.uniform(1000, 5000)\n",
    "    \n",
    "def segmented_number_of_purchases(segment):\n",
    "    \"\"\"\n",
    "    Generate a random number of purchases based on the segment.\n",
    "    \"\"\"\n",
    "    if segment == 'High Value':\n",
    "        return np.random.randint(50, 100)\n",
    "    elif segment == 'Medium Value':\n",
    "        return np.random.randint(20, 50)\n",
    "    else:\n",
    "        return np.random.randint(1, 20)        \n",
    "\n",
    "def generate_customer_data(num_samples):\n",
    "    \"\"\"\n",
    "    Generate synthetic customer data with random values for the features.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "\n",
    "    # Generate random segments for the customers\n",
    "    segments = np.random.choice(['High Value', 'Medium Value', 'Low Value'], num_samples)\n",
    "\n",
    "    customer_ids = np.arange(1, num_samples + 1)\n",
    "    annual_spending = np.array([segmented_anual_spending(segment) for segment in segments])\n",
    "    number_of_purchases = np.array([segmented_number_of_purchases(segment) for segment in segments])\n",
    "    avg_purchase_value = annual_spending / number_of_purchases\n",
    "    ages = np.random.randint(18, 70, num_samples)\n",
    "    tenure = np.random.randint(1, 20, num_samples)\n",
    "    \n",
    "\n",
    "    data = {\n",
    "        'CustomerID': customer_ids,\n",
    "        'AnnualSpending': annual_spending,\n",
    "        'NumberOfPurchases': number_of_purchases,\n",
    "        'AvgPurchaseValue': avg_purchase_value,\n",
    "        'Age': ages,\n",
    "        'Tenure': tenure,\n",
    "        'Segment': segments\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate a larger dataset\n",
    "num_samples = 1000000  # Adjust the number of samples as needed\n",
    "df = generate_customer_data(num_samples)\n",
    "\n",
    "# Drop CustomerID as it is not a useful feature for the model\n",
    "df = df.drop('CustomerID', axis=1)\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df['Segment'] = label_encoder.fit_transform(df['Segment'])\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop('Segment', axis=1)\n",
    "y = df['Segment']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "model = xgb.XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "\n",
    "# Decode the predicted labels back to the original categories\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "print(\"Predicted Segments:\", y_pred_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b7f02f-5072-4f78-9d5a-5b718888db57",
   "metadata": {},
   "source": [
    "### Summary of Predictions\n",
    "In this summary, we can first validate the number of samples in the testing set and the number of predicted segments.\n",
    "Next, we can validate the mapping of the labels to the original categories using the label encoder.\n",
    "Finally, we can display a sample of the testing set with the actual segment and the predicted segment to visually validate the predictions.\n",
    "\n",
    "We can use the following code to summarize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13f7df3f-c329-48c7-990c-d91bfcae53a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING SET COUNT: 200,000\n",
      "PREDICTED SEGMENT COUNTS: 200,000\n",
      "\n",
      "Label Encoder Mapping: {'High Value': 0, 'Low Value': 1, 'Medium Value': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnnualSpending</th>\n",
       "      <th>NumberOfPurchases</th>\n",
       "      <th>AvgPurchaseValue</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Segment</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>987231</th>\n",
       "      <td>18183.770552</td>\n",
       "      <td>54</td>\n",
       "      <td>336.736492</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>High Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79954</th>\n",
       "      <td>18885.464470</td>\n",
       "      <td>56</td>\n",
       "      <td>337.240437</td>\n",
       "      <td>47</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>High Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567130</th>\n",
       "      <td>5480.930999</td>\n",
       "      <td>24</td>\n",
       "      <td>228.372125</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500891</th>\n",
       "      <td>4014.778705</td>\n",
       "      <td>6</td>\n",
       "      <td>669.129784</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Low Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55399</th>\n",
       "      <td>1592.891401</td>\n",
       "      <td>7</td>\n",
       "      <td>227.555914</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Low Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135049</th>\n",
       "      <td>13748.598968</td>\n",
       "      <td>71</td>\n",
       "      <td>193.642239</td>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>High Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733378</th>\n",
       "      <td>3569.020003</td>\n",
       "      <td>6</td>\n",
       "      <td>594.836667</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Low Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732057</th>\n",
       "      <td>3194.654720</td>\n",
       "      <td>3</td>\n",
       "      <td>1064.884907</td>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Low Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51333</th>\n",
       "      <td>5268.953379</td>\n",
       "      <td>34</td>\n",
       "      <td>154.969217</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731479</th>\n",
       "      <td>12403.718712</td>\n",
       "      <td>76</td>\n",
       "      <td>163.206825</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>High Value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AnnualSpending  NumberOfPurchases  AvgPurchaseValue  Age  Tenure  \\\n",
       "987231    18183.770552                 54        336.736492   29      16   \n",
       "79954     18885.464470                 56        337.240437   47      17   \n",
       "567130     5480.930999                 24        228.372125   32      15   \n",
       "500891     4014.778705                  6        669.129784   37       4   \n",
       "55399      1592.891401                  7        227.555914   22       6   \n",
       "135049    13748.598968                 71        193.642239   68      10   \n",
       "733378     3569.020003                  6        594.836667   55       3   \n",
       "732057     3194.654720                  3       1064.884907   48      18   \n",
       "51333      5268.953379                 34        154.969217   36      16   \n",
       "731479    12403.718712                 76        163.206825   41       5   \n",
       "\n",
       "        Segment    prediction  \n",
       "987231        0    High Value  \n",
       "79954         0    High Value  \n",
       "567130        2  Medium Value  \n",
       "500891        1     Low Value  \n",
       "55399         1     Low Value  \n",
       "135049        0    High Value  \n",
       "733378        1     Low Value  \n",
       "732057        1     Low Value  \n",
       "51333         2  Medium Value  \n",
       "731479        0    High Value  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View counts to validate\n",
    "print(f\"\"\"\n",
    "TESTING SET COUNT: {X_test.shape[0]:,.0f}\n",
    "PREDICTED SEGMENT COUNTS: {len(y_pred_labels):,.0f}\n",
    "\"\"\")\n",
    "\n",
    "# View the mapping of labels to validate\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Encoder Mapping:\", label_mapping)\n",
    "\n",
    "predicted_test_df = pd.concat([X_test, y_test.to_frame()], axis=1)\n",
    "predicted_test_df[\"prediction\"] = y_pred_labels\n",
    "\n",
    "predicted_test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a99b2",
   "metadata": {},
   "source": [
    "# Example of one customer record\n",
    "\n",
    "In this example, we have a customer with the following features:\n",
    "- Annual Spending: $12,000\n",
    "- Number of Purchases: 75\n",
    "- Average Purchase Value: $160\n",
    "- Age: 35\n",
    "- Tenure: 15 years\n",
    "\n",
    "We can use the trained model to predict the segment for this customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7148e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Segment for New Customer: High Value\n"
     ]
    }
   ],
   "source": [
    "new_customer_data = {\n",
    "    'AnnualSpending': [12000],\n",
    "    'NumberOfPurchases': [75],\n",
    "    'AvgPurchaseValue': [160],\n",
    "    'Age': [35],\n",
    "    'Tenure': [15]\n",
    "}\n",
    "\n",
    "new_customer_df = pd.DataFrame(new_customer_data)\n",
    "\n",
    "# Make predictions for the new customer data\n",
    "new_customer_pred = model.predict(new_customer_df)\n",
    "new_customer_pred_label = label_encoder.inverse_transform(new_customer_pred)\n",
    "print(\"Predicted Segment for New Customer:\", new_customer_pred_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038365b",
   "metadata": {},
   "source": [
    "# END OF NOTEOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
